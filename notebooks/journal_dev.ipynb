{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from app.analyzer import analyze_entry\n",
    "from app.storage import save_entry, load_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_text = \"\"\"\n",
    "I‚Äôve been feeling overwhelmed by the pace of work lately. Even when I finish something, the to-do list just keeps growing. \n",
    "I know I should be proud of what I accomplish, but I can't help feeling like I'm falling short.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = analyze_entry(journal_text)\n",
    "save_entry(journal_text, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = load_entries()\n",
    "entries[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.storage import load_entries\n",
    "\n",
    "entries = load_entries()\n",
    "\n",
    "# Find the entry by keyword (e.g., 'new Journal')\n",
    "for i, e in enumerate(reversed(entries)):\n",
    "    if \"new Journal\" in e[\"text\"]:\n",
    "        print(f\"Found at index: {-1 - i}\")\n",
    "        print(e[\"text\"])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = entries[-2]\n",
    "print(\"üìù Text:\\n\", entry[\"text\"])\n",
    "print(\"üß† Summary:\\n\", entry[\"summary\"])\n",
    "print(\"üßæ Raw Output:\\n\", entry.get(\"raw_output\", \"No raw output found\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.analyzer import analyze_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = analyze_entry(entry['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_realistic_journals.py\n",
    "# Uses DeepSeek (via Ollama) to create 150 diverse journal entries\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "\n",
    "# Constants\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "OUTPUT_PATH = \"/Users/Additional Storage/ML Projects/Journal app/data/generated_deepseek_entries.jsonl\"\n",
    "\n",
    "# Emotion/theme seeds for diversity\n",
    "emotions_pool = [\n",
    "    \"anxiety\", \"joy\", \"loneliness\", \"hope\", \"confusion\", \"pride\", \"grief\", \"boredom\", \"motivation\",\n",
    "    \"excitement\", \"fear\", \"regret\", \"curiosity\", \"burnout\", \"peace\"\n",
    "]\n",
    "topics_pool = [\n",
    "    \"relationships\", \"work stress\", \"family dynamics\", \"career growth\", \"mental health\", \"self-discovery\",\n",
    "    \"routine fatigue\", \"health journey\", \"romantic feelings\", \"loss\", \"uncertainty about future\",\n",
    "    \"celebrating a win\", \"dealing with rejection\", \"spiritual questioning\"\n",
    "]\n",
    "\n",
    "# Prompt to generate realistic journal text\n",
    "ENTRY_GENERATION_PROMPT = \"\"\"\n",
    "You're a human writing a private journal.\n",
    "Your tone should be raw, informal, and personal.\n",
    "Write a journal entry about feeling {emotion} today, with thoughts related to {topic}.\n",
    "Include emotion, thought loops, and sensory detail if helpful.\n",
    "Keep it between 4‚Äì8 sentences.\n",
    "Do not include headings or lists.\n",
    "Just return the journal text.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "# Generate a single journal text from deepseek\n",
    "def generate_journal_text(emotion, topic):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a human journaling assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": ENTRY_GENERATION_PROMPT.format(emotion=emotion, topic=topic)}\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(OLLAMA_URL, json=payload)\n",
    "        raw = response.json()[\"message\"][\"content\"].strip()\n",
    "        cleaned = re.sub(r\"<think>.*?</think>\", \"\", raw, flags=re.DOTALL).strip()\n",
    "        return cleaned\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to generate entry for {emotion} + {topic}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Generate realistic timestamp\n",
    "def random_timestamp(start_year=2024, end_year=2025):\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(end_year, 12, 31)\n",
    "    total_days = (end_date - start_date).days\n",
    "    random_days = random.randint(0, total_days)\n",
    "    random_seconds = random.randint(0, 86400)\n",
    "    return (start_date + timedelta(days=random_days, seconds=random_seconds)).isoformat()\n",
    "\n",
    "# Generate entries and save\n",
    "entries = []\n",
    "combos = list(set((e, t) for e in emotions_pool for t in topics_pool))\n",
    "random.shuffle(combos)\n",
    "\n",
    "total = 2\n",
    "print(f\"üß† Generating {total} entries via DeepSeek‚Ä¶\")\n",
    "\n",
    "for i in range(total):\n",
    "    emotion, topic = combos[i % len(combos)]\n",
    "    text = generate_journal_text(emotion, topic)\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    entry = {\n",
    "        \"timestamp\": random_timestamp(),\n",
    "        \"text\": text,\n",
    "        \"summary\": \"\",  # To be filled by your analyzer\n",
    "        \"emotions\": [],\n",
    "        \"patterns\": [],\n",
    "        \"themes\": [],\n",
    "        \"ai_thoughts\": \"\",\n",
    "        \"raw_output\": \"\"\n",
    "    }\n",
    "    entries.append(entry)\n",
    "    print(f\"‚úÖ {i+1}/{total}: {emotion}, {topic}\")\n",
    "    time.sleep(1.5)  # Optional pacing if DeepSeek needs time\n",
    "\n",
    "# Save to .jsonl\n",
    "with open(OUTPUT_PATH, \"w\") as f:\n",
    "    for entry in entries:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"\\n‚úÖ Done. Saved {len(entries)} entries to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "\n",
    "with open(OUTPUT_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        entries.append(json.loads(line.strip()))\n",
    "\n",
    "# Now you can access individual ones like:\n",
    "print(entries[0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "\n",
    "with open(OUTPUT_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        entries.append(json.loads(line.strip()))\n",
    "\n",
    "# Now you can access individual ones like:\n",
    "print(entries[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "\n",
    "with open(OUTPUT_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        entries.append(json.loads(line.strip()))\n",
    "\n",
    "# Now you can access individual ones like:\n",
    "print(entries[5]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_realistic_journals.py\n",
    "import json, random, re, requests\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "OUTPUT_PATH = \"/Users/Additional Storage/ML Projects/Journal app/data/test_generated_entries.jsonl\"\n",
    "TOTAL_ENTRIES = 100\n",
    "TEMPERATURE = 0.8\n",
    "\n",
    "emotions = [\"anxiety\", \"joy\", \"confusion\", \"hope\", \"frustration\", \"nostalgia\", \"burnout\", \"contentment\", \"loneliness\"]\n",
    "topics = [\"work stress\", \"relationships\", \"self-doubt\", \"mental health\", \"growth\", \"grief\", \"career uncertainty\", \"romantic confusion\", \"burnout recovery\", \"loneliness\", \"change and transition\", \"creative block\", \"financial pressure\", \"family expectations\", \"isolation\", \"identity\", \"body image\", \"success anxiety\", \"fear of failure\", \"disconnection from others\", \"social anxiety\"]\n",
    "\n",
    "GEN_PROMPT = \"\"\"\n",
    "You are a private journal writer.\n",
    "Write a thoughtful, emotionally realistic journal entry from someone who is experiencing the emotion: {emotion}, in the context of: {topic}.\n",
    "The tone should feel personal and introspective ‚Äî not scripted / cmputer written, it should sound like a normal decently educated indian english writer.\n",
    "Write 4‚Äì8 flowing sentences, including sensory details and authentic reflection.\n",
    "Ensure good grammar and spelling, and avoid artificial phrasing or markdown.\n",
    "Return only the journal entry text with no commentary or extra formatting.\n",
    "\"\"\"\n",
    "\n",
    "def generate_entry(emotion, topic):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a human journaling assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": GEN_PROMPT.format(emotion=emotion, topic=topic)}\n",
    "        ],\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        raw = res.json()[\"message\"][\"content\"].strip()\n",
    "        return re.sub(r\"<think>.*?</think>\", \"\", raw, flags=re.DOTALL).strip()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error for {emotion}/{topic}: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_entry(text):\n",
    "    ANALYSIS_PROMPT = \"\"\"\n",
    "You are a compassionate AI assistant trained to analyze journal entries.\n",
    "Return ONLY a valid raw JSON object with the following keys:\n",
    "  - summary: a one-sentence paraphrase of the overall entry\n",
    "  - emotions: list of 1‚Äì3 dominant emotional states\n",
    "  - patterns: list of up to 3 cognitive distortions (e.g., catastrophizing)\n",
    "  - themes: list of up to 3 core life topics the entry relates to\n",
    "\n",
    "Do NOT include explanations or markdown.\n",
    "\"\"\"\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": ANALYSIS_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        content = res.json()[\"message\"][\"content\"].strip()\n",
    "        match = re.search(r\"{.*}\", content, re.DOTALL)\n",
    "        return json.loads(match.group(0)) if match else None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Analysis error: {e}\")\n",
    "        return None\n",
    "\n",
    "def random_timestamp():\n",
    "    start = datetime(2024, 1, 1)\n",
    "    end = datetime(2024, 12, 31)\n",
    "    delta = end - start\n",
    "    offset = timedelta(days=random.randint(0, delta.days), hours=random.randint(18, 22), minutes=random.randint(0, 59))\n",
    "    return (start + offset).isoformat()\n",
    "\n",
    "def emotion_for_month(month):\n",
    "    bias_map = {\n",
    "        1: [\"anxiety\", \"burnout\"], 2: [\"anxiety\"], 3: [\"confusion\"], 4: [\"hope\"], 5: [\"burnout\"],\n",
    "        6: [\"joy\", \"contentment\"], 7: [\"joy\"], 8: [\"nostalgia\"], 9: [\"confusion\", \"anxiety\"],\n",
    "        10: [\"nostalgia\", \"loneliness\"], 11: [\"loneliness\"], 12: [\"loneliness\", \"contentment\"]\n",
    "    }\n",
    "    biased = bias_map.get(month, [])\n",
    "    return random.choice(biased) if biased and random.random() < 0.6 else random.choice(emotions)\n",
    "\n",
    "# Load existing\n",
    "existing = []\n",
    "if Path(OUTPUT_PATH).exists():\n",
    "    with open(OUTPUT_PATH) as f:\n",
    "        existing = [json.loads(line) for line in f if line.strip()]\n",
    "existing_ts = set(e[\"timestamp\"] for e in existing)\n",
    "\n",
    "# Generate\n",
    "new_entries = []\n",
    "for _ in range(TOTAL_ENTRIES):\n",
    "    ts = random_timestamp()\n",
    "    if ts in existing_ts:\n",
    "        continue\n",
    "    emo = emotion_for_month(datetime.fromisoformat(ts).month)\n",
    "    top = random.choice(topics)\n",
    "    text = generate_entry(emo, top)\n",
    "    if not text:\n",
    "        continue\n",
    "    analysis = analyze_entry(text)\n",
    "    if not analysis:\n",
    "        continue\n",
    "    new_entries.append({\n",
    "        \"timestamp\": ts,\n",
    "        \"text\": text,\n",
    "        \"analysis\": analysis\n",
    "    })\n",
    "    print(f\"‚úÖ {ts} ‚Äî {emo} | {top}\")\n",
    "\n",
    "# Save all\n",
    "with open(OUTPUT_PATH, \"w\") as f:\n",
    "    for e in existing + new_entries:\n",
    "        f.write(json.dumps(e) + \"\\n\")\n",
    "\n",
    "print(f\"\\nüìÑ Saved {len(new_entries)} new entries to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 1 entries\n",
      "\n",
      "üîç First Entry:\n",
      "{\n",
      "  \"text\": \"Ok let's see I feel like I have been mostly wasting time durign the last weekened, I feel sad about it. but atleast I am working on this jounal app so I guess that is good right? someone please tell me I am feeling down!\",\n",
      "  \"analysis\": {\n",
      "    \"summary\": \"The individual acknowledges their feelings of time-wastage and sadness while reflecting on their ongoing journaling as a coping strategy.\",\n",
      "    \"emotions\": [\n",
      "      \"sadness\",\n",
      "      \"time-wastage anxiety\"\n",
      "    ],\n",
      "    \"patterns\": [\n",
      "      \"catastrophizing (relating sadness to ongoing activity)\",\n",
      "      \"self-blame for past actions\"\n",
      "    ],\n",
      "    \"themes\": [\n",
      "      \"time management stress\",\n",
      "      \"journaling as stress relief\"\n",
      "    ],\n",
      "    \"ai_thoughts\": \"Alright, I need to analyze the user's journal entry and provide a summary, primary emotions, cognitive distortions, and core themes based on their content.\\n\\nFirst, reading the entry: \\\"Ok let's see I feel like I have been mostly wasting time during the last weekend, I feel sad about it. But at least I'm working on this journal app so I guess that is good right? Someone please tell me I am feeling down!\\\"\\n\\nI notice the user mentions feeling sad and has an activity (journaling) as a coping mechanism.\\n\\nFor the summary: They acknowledge their time-wasting but are trying to stay positive by documenting their process. So, \\\"The individual acknowledges their feelings of time-wastage and sadness while reflecting on their ongoing journaling as a coping strategy.\\\"\\n\\nPrimary emotions: Sadness is clearly present due to feeling down or regret. The mention of time-wasting could also hint at anxiety about wasted time, though it's not explicitly stated.\\n\\nCognitive distortions: The user seems to use catastrophizing when they feel sad because they're associating their sadness with the activity (journaling). Also, they have self-blame by not taking responsibility for their time-wasting. There might be an expectation distortion, where they expect positive outcomes from the journal app.\\n\\nCore themes would include work stress or time management issues related to the past weekend and relationships if that's part of the context, though it's not explicitly mentioned here.\\n\\nPutting it all together into JSON format as per the instructions.\",\n",
      "    \"raw_output\": \"<think>\\nAlright, I need to analyze the user's journal entry and provide a summary, primary emotions, cognitive distortions, and core themes based on their content.\\n\\nFirst, reading the entry: \\\"Ok let's see I feel like I have been mostly wasting time during the last weekend, I feel sad about it. But at least I'm working on this journal app so I guess that is good right? Someone please tell me I am feeling down!\\\"\\n\\nI notice the user mentions feeling sad and has an activity (journaling) as a coping mechanism.\\n\\nFor the summary: They acknowledge their time-wasting but are trying to stay positive by documenting their process. So, \\\"The individual acknowledges their feelings of time-wastage and sadness while reflecting on their ongoing journaling as a coping strategy.\\\"\\n\\nPrimary emotions: Sadness is clearly present due to feeling down or regret. The mention of time-wasting could also hint at anxiety about wasted time, though it's not explicitly stated.\\n\\nCognitive distortions: The user seems to use catastrophizing when they feel sad because they're associating their sadness with the activity (journaling). Also, they have self-blame by not taking responsibility for their time-wasting. There might be an expectation distortion, where they expect positive outcomes from the journal app.\\n\\nCore themes would include work stress or time management issues related to the past weekend and relationships if that's part of the context, though it's not explicitly mentioned here.\\n\\nPutting it all together into JSON format as per the instructions.\\n</think>\\n\\n```json\\n{\\n  \\\"summary\\\": \\\"The individual acknowledges their feelings of time-wastage and sadness while reflecting on their ongoing journaling as a coping strategy.\\\",\\n  \\\"emotions\\\": [\\\"sadness\\\", \\\"time-wastage anxiety\\\"],\\n  \\\"patterns\\\": [\\\"catastrophizing (relating sadness to ongoing activity)\\\", \\\"self-blame for past actions\\\"],\\n  \\\"themes\\\": [\\\"time management stress\\\", \\\"journaling as stress relief\\\"]\\n}\\n```\",\n",
      "    \"text\": \"Ok let's see I feel like I have been mostly wasting time durign the last weekened, I feel sad about it. but atleast I am working on this jounal app so I guess that is good right? someone please tell me I am feeling down!\",\n",
      "    \"timestamp\": \"2025-06-01T17:38:52.651403\"\n",
      "  },\n",
      "  \"timestamp\": \"2025-06-01T17:39:07.075072\"\n",
      "}\n",
      "\n",
      "üß™ Entry has nested 'analysis' ‚Äî keys: dict_keys(['summary', 'emotions', 'patterns', 'themes', 'ai_thoughts', 'raw_output', 'text', 'timestamp'])\n",
      "\n",
      "üßæ DataFrame columns: ['text', 'analysis', 'timestamp', 'summary', 'emotions', 'patterns', 'themes', 'ai_thoughts', 'raw_output']\n",
      "\n",
      "üìå Sample Row:\n",
      "text           Ok let's see I feel like I have been mostly wa...\n",
      "analysis       {'summary': 'The individual acknowledges their...\n",
      "timestamp                             2025-06-01T17:38:52.651403\n",
      "summary        The individual acknowledges their feelings of ...\n",
      "emotions                         [sadness, time-wastage anxiety]\n",
      "patterns       [catastrophizing (relating sadness to ongoing ...\n",
      "themes         [time management stress, journaling as stress ...\n",
      "ai_thoughts    Alright, I need to analyze the user's journal ...\n",
      "raw_output     <think>\\nAlright, I need to analyze the user's...\n",
      "Name: 0, dtype: object\n",
      "\n",
      "üö® Entries missing 'emotions': 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your JSONL file\n",
    "file_path = \"/Users/Additional Storage/ML Projects/Journal app/data/journal_entries.jsonl\"\n",
    "\n",
    "# Step 1: Load and inspect structure\n",
    "entries = []\n",
    "with open(file_path, \"r\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        try:\n",
    "            entry = json.loads(line.strip())\n",
    "            entries.append(entry)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ùå Error parsing line {i}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(entries)} entries\")\n",
    "\n",
    "# Step 2: Print first entry's structure\n",
    "print(\"\\nüîç First Entry:\")\n",
    "print(json.dumps(entries[0], indent=2))\n",
    "\n",
    "# Step 3: Check if nested\n",
    "if \"analysis\" in entries[0]:\n",
    "    print(\"\\nüß™ Entry has nested 'analysis' ‚Äî keys:\", entries[0][\"analysis\"].keys())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No 'analysis' key found in first entry.\")\n",
    "\n",
    "# Step 4: Promote nested fields if necessary\n",
    "for entry in entries:\n",
    "    if \"analysis\" in entry:\n",
    "        entry.update(entry[\"analysis\"])\n",
    "\n",
    "# Step 5: Convert to DataFrame and check columns\n",
    "df = pd.DataFrame(entries)\n",
    "print(\"\\nüßæ DataFrame columns:\", df.columns.tolist())\n",
    "\n",
    "# Step 6: Look at typical row for visual inspection\n",
    "print(\"\\nüìå Sample Row:\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "# Optional: check for missing 'emotions' values\n",
    "missing_emotions = df[\"emotions\"].isnull().sum()\n",
    "print(f\"\\nüö® Entries missing 'emotions': {missing_emotions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
