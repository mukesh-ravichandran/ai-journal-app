{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from app.analyzer import analyze_entry\n",
    "from app.storage import save_entry, load_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "journal_text = \"\"\"\n",
    "I‚Äôve been feeling overwhelmed by the pace of work lately. Even when I finish something, the to-do list just keeps growing. \n",
    "I know I should be proud of what I accomplish, but I can't help feeling like I'm falling short.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Entry saved at 2025-06-09T20:35:22.553640\n",
      "üß† Appended to RAG file: /Users/Additional Storage/ML Projects/Journal app/notebooks/../app/../data/rag/rag_journal_entries.jsonl\n"
     ]
    }
   ],
   "source": [
    "result = analyze_entry(journal_text)\n",
    "save_entry(journal_text, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"\\nI‚Äôve been feeling overwhelmed by the pace of work lately. Even when I finish something, the to-do list just keeps growing. \\nI know I should be proud of what I accomplish, but I can't help feeling like I'm falling short.\\n\",\n",
       " 'analysis': {'summary': 'Feeling overwhelmed by the pace of work despite completing tasks.',\n",
       "  'emotions': ['overwhelmed', 'frustrated'],\n",
       "  'patterns': ['catastrophizing', 'self-blame', 'hopelessness'],\n",
       "  'themes': ['work stress', 'personal achievements', 'work balance'],\n",
       "  'ai_thoughts': \"Okay, so I need to analyze this journal entry and provide a summary, primary emotions, cognitive distortions, and core themes using JSON format. Let me break it down step by step.\\n\\nFirst, the user is talking about being overwhelmed by work pace. They finish tasks but the list keeps growing. That's creating stress or anxiety because there's always more to do even after completing something. So the summary should capture that feeling of overwhelm and the ongoing tasks.\\n\\nNext, the emotions involved. They mention feeling overwhelmed and maybe frustration because they feel like they're not meeting their own expectations by being proud of their work. So I'd say overwhelmed and frustrated as primary emotions.\\n\\nFor cognitive distortions, the user knows they're proud but can't help feeling they're falling short. This sounds like catastrophizing‚Äîoverestimating negative outcomes. They might also be self-blame thinking they should have done more or better, which is another distortion. Additionally, there's probably a sense of hopelessness because work keeps piling up despite finishing tasks.\\n\\nCore themes would revolve around the work environment and the stress it causes. The constant growth of the to-do list points to work stress. The frustration about being proud could relate to personal achievements or expectations, which might fall under personal achievements or work balance. The feeling of overwhelm is more directly tied to work itself.\",\n",
       "  'raw_output': '<think>\\nOkay, so I need to analyze this journal entry and provide a summary, primary emotions, cognitive distortions, and core themes using JSON format. Let me break it down step by step.\\n\\nFirst, the user is talking about being overwhelmed by work pace. They finish tasks but the list keeps growing. That\\'s creating stress or anxiety because there\\'s always more to do even after completing something. So the summary should capture that feeling of overwhelm and the ongoing tasks.\\n\\nNext, the emotions involved. They mention feeling overwhelmed and maybe frustration because they feel like they\\'re not meeting their own expectations by being proud of their work. So I\\'d say overwhelmed and frustrated as primary emotions.\\n\\nFor cognitive distortions, the user knows they\\'re proud but can\\'t help feeling they\\'re falling short. This sounds like catastrophizing‚Äîoverestimating negative outcomes. They might also be self-blame thinking they should have done more or better, which is another distortion. Additionally, there\\'s probably a sense of hopelessness because work keeps piling up despite finishing tasks.\\n\\nCore themes would revolve around the work environment and the stress it causes. The constant growth of the to-do list points to work stress. The frustration about being proud could relate to personal achievements or expectations, which might fall under personal achievements or work balance. The feeling of overwhelm is more directly tied to work itself.\\n</think>\\n\\n```json\\n{\\n  \"summary\": \"Feeling overwhelmed by the pace of work despite completing tasks.\",\\n  \"emotions\": [\"overwhelmed\", \"frustrated\"],\\n  \"patterns\": [\"catastrophizing\", \"self-blame\", \"hopelessness\"],\\n  \"themes\": [\"work stress\", \"personal achievements\", \"work balance\"]\\n}\\n```'},\n",
       " 'timestamp': '2025-06-09T20:35:22.553640'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = load_entries()\n",
    "entries[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.storage import load_entries\n",
    "\n",
    "entries = load_entries()\n",
    "\n",
    "# Find the entry by keyword (e.g., 'new Journal')\n",
    "for i, e in enumerate(reversed(entries)):\n",
    "    if \"new Journal\" in e[\"text\"]:\n",
    "        print(f\"Found at index: {-1 - i}\")\n",
    "        print(e[\"text\"])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Text:\n",
      " I am checking if the new RAG works, I hope it does and le'ts see - I am nervous about it 123456789 practicing counting numbers let's try something new may be that will workkk umm lets see RAG\n",
      "NLP\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m entry \u001b[38;5;241m=\u001b[39m entries[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìù Text:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müß† Summary:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, entry[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müßæ Raw Output:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, entry\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_output\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo raw output found\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'summary'"
     ]
    }
   ],
   "source": [
    "entry = entries[-2]\n",
    "print(\"üìù Text:\\n\", entry[\"text\"])\n",
    "print(\"üß† Summary:\\n\", entry[\"summary\"])\n",
    "print(\"üßæ Raw Output:\\n\", entry.get(\"raw_output\", \"No raw output found\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.analyzer import analyze_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = analyze_entry(entry['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_realistic_journals.py\n",
    "# Uses DeepSeek (via Ollama) to create 150 diverse journal entries\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "\n",
    "# Constants\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "OUTPUT_PATH = \"/Users/Additional Storage/ML Projects/Journal app/data/generated_deepseek_entries.jsonl\"\n",
    "\n",
    "# Emotion/theme seeds for diversity\n",
    "emotions_pool = [\n",
    "    \"anxiety\", \"joy\", \"loneliness\", \"hope\", \"confusion\", \"pride\", \"grief\", \"boredom\", \"motivation\",\n",
    "    \"excitement\", \"fear\", \"regret\", \"curiosity\", \"burnout\", \"peace\"\n",
    "]\n",
    "topics_pool = [\n",
    "    \"relationships\", \"work stress\", \"family dynamics\", \"career growth\", \"mental health\", \"self-discovery\",\n",
    "    \"routine fatigue\", \"health journey\", \"romantic feelings\", \"loss\", \"uncertainty about future\",\n",
    "    \"celebrating a win\", \"dealing with rejection\", \"spiritual questioning\"\n",
    "]\n",
    "\n",
    "# Prompt to generate realistic journal text\n",
    "ENTRY_GENERATION_PROMPT = \"\"\"\n",
    "You're a human writing a private journal.\n",
    "Your tone should be raw, informal, and personal.\n",
    "Write a journal entry about feeling {emotion} today, with thoughts related to {topic}.\n",
    "Include emotion, thought loops, and sensory detail if helpful.\n",
    "Keep it between 4‚Äì8 sentences.\n",
    "Do not include headings or lists.\n",
    "Just return the journal text.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "# Generate a single journal text from deepseek\n",
    "def generate_journal_text(emotion, topic):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a human journaling assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": ENTRY_GENERATION_PROMPT.format(emotion=emotion, topic=topic)}\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(OLLAMA_URL, json=payload)\n",
    "        raw = response.json()[\"message\"][\"content\"].strip()\n",
    "        cleaned = re.sub(r\"<think>.*?</think>\", \"\", raw, flags=re.DOTALL).strip()\n",
    "        return cleaned\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to generate entry for {emotion} + {topic}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Generate realistic timestamp\n",
    "def random_timestamp(start_year=2024, end_year=2025):\n",
    "    start_date = datetime(start_year, 1, 1)\n",
    "    end_date = datetime(end_year, 12, 31)\n",
    "    total_days = (end_date - start_date).days\n",
    "    random_days = random.randint(0, total_days)\n",
    "    random_seconds = random.randint(0, 86400)\n",
    "    return (start_date + timedelta(days=random_days, seconds=random_seconds)).isoformat()\n",
    "\n",
    "# Generate entries and save\n",
    "entries = []\n",
    "combos = list(set((e, t) for e in emotions_pool for t in topics_pool))\n",
    "random.shuffle(combos)\n",
    "\n",
    "total = 2\n",
    "print(f\"üß† Generating {total} entries via DeepSeek‚Ä¶\")\n",
    "\n",
    "for i in range(total):\n",
    "    emotion, topic = combos[i % len(combos)]\n",
    "    text = generate_journal_text(emotion, topic)\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    entry = {\n",
    "        \"timestamp\": random_timestamp(),\n",
    "        \"text\": text,\n",
    "        \"summary\": \"\",  # To be filled by your analyzer\n",
    "        \"emotions\": [],\n",
    "        \"patterns\": [],\n",
    "        \"themes\": [],\n",
    "        \"ai_thoughts\": \"\",\n",
    "        \"raw_output\": \"\"\n",
    "    }\n",
    "    entries.append(entry)\n",
    "    print(f\"‚úÖ {i+1}/{total}: {emotion}, {topic}\")\n",
    "    time.sleep(1.5)  # Optional pacing if DeepSeek needs time\n",
    "\n",
    "# Save to .jsonl\n",
    "with open(OUTPUT_PATH, \"w\") as f:\n",
    "    for entry in entries:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"\\n‚úÖ Done. Saved {len(entries)} entries to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "\n",
    "with open(OUTPUT_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        entries.append(json.loads(line.strip()))\n",
    "\n",
    "# Now you can access individual ones like:\n",
    "print(entries[0][\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "\n",
    "with open(OUTPUT_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        entries.append(json.loads(line.strip()))\n",
    "\n",
    "# Now you can access individual ones like:\n",
    "print(entries[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "\n",
    "with open(OUTPUT_PATH, \"r\") as f:\n",
    "    for line in f:\n",
    "        entries.append(json.loads(line.strip()))\n",
    "\n",
    "# Now you can access individual ones like:\n",
    "print(entries[5]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_realistic_journals.py\n",
    "import json, random, re, requests\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "OUTPUT_PATH = \"/Users/Additional Storage/ML Projects/Journal app/data/test_generated_entries.jsonl\"\n",
    "TOTAL_ENTRIES = 100\n",
    "TEMPERATURE = 0.8\n",
    "\n",
    "emotions = [\"anxiety\", \"joy\", \"confusion\", \"hope\", \"frustration\", \"nostalgia\", \"burnout\", \"contentment\", \"loneliness\"]\n",
    "topics = [\"work stress\", \"relationships\", \"self-doubt\", \"mental health\", \"growth\", \"grief\", \"career uncertainty\", \"romantic confusion\", \"burnout recovery\", \"loneliness\", \"change and transition\", \"creative block\", \"financial pressure\", \"family expectations\", \"isolation\", \"identity\", \"body image\", \"success anxiety\", \"fear of failure\", \"disconnection from others\", \"social anxiety\"]\n",
    "\n",
    "GEN_PROMPT = \"\"\"\n",
    "You are a private journal writer.\n",
    "Write a thoughtful, emotionally realistic journal entry from someone who is experiencing the emotion: {emotion}, in the context of: {topic}.\n",
    "The tone should feel personal and introspective ‚Äî not scripted / cmputer written, it should sound like a normal decently educated indian english writer.\n",
    "Write 4‚Äì8 flowing sentences, including sensory details and authentic reflection.\n",
    "Ensure good grammar and spelling, and avoid artificial phrasing or markdown.\n",
    "Return only the journal entry text with no commentary or extra formatting.\n",
    "\"\"\"\n",
    "\n",
    "def generate_entry(emotion, topic):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a human journaling assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": GEN_PROMPT.format(emotion=emotion, topic=topic)}\n",
    "        ],\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        raw = res.json()[\"message\"][\"content\"].strip()\n",
    "        return re.sub(r\"<think>.*?</think>\", \"\", raw, flags=re.DOTALL).strip()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error for {emotion}/{topic}: {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_entry(text):\n",
    "    ANALYSIS_PROMPT = \"\"\"\n",
    "You are a compassionate AI assistant trained to analyze journal entries.\n",
    "Return ONLY a valid raw JSON object with the following keys:\n",
    "  - summary: a one-sentence paraphrase of the overall entry\n",
    "  - emotions: list of 1‚Äì3 dominant emotional states\n",
    "  - patterns: list of up to 3 cognitive distortions (e.g., catastrophizing)\n",
    "  - themes: list of up to 3 core life topics the entry relates to\n",
    "\n",
    "Do NOT include explanations or markdown.\n",
    "\"\"\"\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": ANALYSIS_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        content = res.json()[\"message\"][\"content\"].strip()\n",
    "        match = re.search(r\"{.*}\", content, re.DOTALL)\n",
    "        return json.loads(match.group(0)) if match else None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Analysis error: {e}\")\n",
    "        return None\n",
    "\n",
    "def random_timestamp():\n",
    "    start = datetime(2024, 1, 1)\n",
    "    end = datetime(2024, 12, 31)\n",
    "    delta = end - start\n",
    "    offset = timedelta(days=random.randint(0, delta.days), hours=random.randint(18, 22), minutes=random.randint(0, 59))\n",
    "    return (start + offset).isoformat()\n",
    "\n",
    "def emotion_for_month(month):\n",
    "    bias_map = {\n",
    "        1: [\"anxiety\", \"burnout\"], 2: [\"anxiety\"], 3: [\"confusion\"], 4: [\"hope\"], 5: [\"burnout\"],\n",
    "        6: [\"joy\", \"contentment\"], 7: [\"joy\"], 8: [\"nostalgia\"], 9: [\"confusion\", \"anxiety\"],\n",
    "        10: [\"nostalgia\", \"loneliness\"], 11: [\"loneliness\"], 12: [\"loneliness\", \"contentment\"]\n",
    "    }\n",
    "    biased = bias_map.get(month, [])\n",
    "    return random.choice(biased) if biased and random.random() < 0.6 else random.choice(emotions)\n",
    "\n",
    "# Load existing\n",
    "existing = []\n",
    "if Path(OUTPUT_PATH).exists():\n",
    "    with open(OUTPUT_PATH) as f:\n",
    "        existing = [json.loads(line) for line in f if line.strip()]\n",
    "existing_ts = set(e[\"timestamp\"] for e in existing)\n",
    "\n",
    "# Generate\n",
    "new_entries = []\n",
    "for _ in range(TOTAL_ENTRIES):\n",
    "    ts = random_timestamp()\n",
    "    if ts in existing_ts:\n",
    "        continue\n",
    "    emo = emotion_for_month(datetime.fromisoformat(ts).month)\n",
    "    top = random.choice(topics)\n",
    "    text = generate_entry(emo, top)\n",
    "    if not text:\n",
    "        continue\n",
    "    analysis = analyze_entry(text)\n",
    "    if not analysis:\n",
    "        continue\n",
    "    new_entries.append({\n",
    "        \"timestamp\": ts,\n",
    "        \"text\": text,\n",
    "        \"analysis\": analysis\n",
    "    })\n",
    "    print(f\"‚úÖ {ts} ‚Äî {emo} | {top}\")\n",
    "\n",
    "# Save all\n",
    "with open(OUTPUT_PATH, \"w\") as f:\n",
    "    for e in existing + new_entries:\n",
    "        f.write(json.dumps(e) + \"\\n\")\n",
    "\n",
    "print(f\"\\nüìÑ Saved {len(new_entries)} new entries to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "DATA_DIR = \"/Users/Additional Storage/ML Projects/Journal app/data\"\n",
    "\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    if filename.endswith(\".jsonl\") and not filename.startswith(\"rag_\"):\n",
    "        input_path = os.path.join(DATA_DIR, filename)\n",
    "        output_path = os.path.join(DATA_DIR, f\"rag_{filename}\")\n",
    "\n",
    "        rag_entries = []\n",
    "        with open(input_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    entry = json.loads(line.strip())\n",
    "                    rag_doc = {\n",
    "                        \"content\": entry.get(\"text\", \"\"),\n",
    "                        \"metadata\": {\n",
    "                            \"timestamp\": entry.get(\"timestamp\"),\n",
    "                            \"themes\": entry.get(\"analysis\", {}).get(\"themes\", []),\n",
    "                            \"emotions\": entry.get(\"analysis\", {}).get(\"emotions\", [])\n",
    "                        }\n",
    "                    }\n",
    "                    rag_entries.append(rag_doc)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"‚ùå Skipped malformed line in {filename}\")\n",
    "\n",
    "        with open(output_path, \"w\") as f:\n",
    "            for doc in rag_entries:\n",
    "                f.write(json.dumps(doc) + \"\\n\")\n",
    "\n",
    "        print(f\"‚úÖ Created {output_path} with {len(rag_entries)} entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"/Users/Additional Storage/ML Projects/Journal app/data\"\n",
    "jsonl_files = [f for f in os.listdir(data_dir) if f.endswith(\".jsonl\") and not f.startswith(\"rag_\")]\n",
    "print(jsonl_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for file in jsonl_files:\n",
    "    print(f\"\\nüìÇ Checking: {file}\")\n",
    "    path = os.path.join(data_dir, file)\n",
    "    with open(path) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                obj = json.loads(line.strip())\n",
    "                if \"timestamp\" not in obj:\n",
    "                    print(f\"‚ùå Missing timestamp at line {i+1}: {obj}\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"‚ö†Ô∏è Malformed JSON at line {i+1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1 clean entries\n",
      "‚ùå 0 bad entries\n"
     ]
    }
   ],
   "source": [
    "clean_entries = []\n",
    "bad_entries = []\n",
    "\n",
    "with open(os.path.join(data_dir, \"journal_entries.jsonl\")) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        try:\n",
    "            obj = json.loads(line.strip())\n",
    "            if \"timestamp\" in obj:\n",
    "                clean_entries.append(obj)\n",
    "            else:\n",
    "                bad_entries.append((i + 1, obj))\n",
    "        except json.JSONDecodeError as e:\n",
    "            bad_entries.append((i + 1, f\"Malformed JSON: {e}\"))\n",
    "\n",
    "print(f\"‚úÖ {len(clean_entries)} clean entries\")\n",
    "print(f\"‚ùå {len(bad_entries)} bad entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in jsonl_files:\n",
    "    print(f\"\\nüìÅ Checking: {file}\")\n",
    "    path = os.path.join(data_dir, file)\n",
    "    with open(path) as f:\n",
    "        for i, line in enumerate(f):\n",
    "            try:\n",
    "                obj = json.loads(line.strip())\n",
    "                if \"timestamp\" not in obj:\n",
    "                    print(f\"‚ùå {file} line {i+1} is missing timestamp:\\n{obj}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error in {file} line {i+1}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [json.loads(line.strip()) for line in open(path)]\n",
    "entries.sort(key=lambda x: x[\"timestamp\"], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries: 2\n",
      "Last entry preview: [{'content': \"I am checking if the new RAG works, I hope it does and le'ts see - I am nervous about it 123456789 practicing counting numbers\", 'metadata': {'timestamp': '2025-06-04T22:36:40.885776', 'themes': ['anxiety about technology', 'practicing a routine task', 'new tool anxiety'], 'emotions': ['anxiety', 'nervousness']}}, {'content': \"I am checking if the new RAG works, I hope it does and le'ts see - I am nervous about it 123456789 practicing counting numbers let's try something new may be that will workkk umm lets see RAG\\nNLP\", 'metadata': {'timestamp': '2025-06-04T22:38:19.492991', 'themes': ['testing RAG model', 'trying something new', 'experimentation with AI'], 'emotions': ['nervousness', 'uncertainty', 'excitement']}}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "rag_path = '/Users/Additional Storage/ML Projects/Journal app/data/rag/rag_journal_entries.jsonl'\n",
    "\n",
    "with open(rag_path, \"r\") as f:\n",
    "    lines = [json.loads(line) for line in f]\n",
    "\n",
    "print(f\"Total entries: {len(lines)}\")\n",
    "print(\"Last entry preview:\", lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 119 journal entries.\n",
      "üìù First entry:\n",
      "{'timestamp': '2024-01-05T18:37:00', 'text': 'The room was dim, the hum of an fluorescent bulb barely audible among the heavy silence. I sat in my corner, sipping tea from a teacup so small it felt like a personal pronouncement against my cup size. The weight of tomorrow‚Äôs presentation gnawed at me, its preparation having worn a toll not just on my body but on my soul. The tension stretched taught across my shoulders, each muscle a knot where nerves had knotted them before, but today, I felt it was different. The heart thrummed faster than usual, the pounding met with a faint flutter, as if it were racing against an invisible clock.\\n\\nMy fingers trembled involuntarily on the edge of my laptop, fingers that had once clapped together so neatly during revisions at work. The keys beneath them felt cold to the touch now, the same cold that made my palms turn prune-like. I tried to quiet the noise inside me, to compartmentalize the fear and dread that pressed too firmly into my chest. But it kept coming, a voice from the past, one that spoke of perfection and inadequacy, of what others might know but couldn‚Äôt say.\\n\\nI reached for the cup of tea again, the mug cold against my palm as I drank deeply, each sip a reminder of the sleepless nights and the endless loop of doubt. The caffeine buzzed in my brain like static crackling on a radio, jolts of energy interspersed with waves of anxiety that made my head spin. But here I was, in this moment, feeling it all. The fear, the tension, the quiet acceptance of what had been brewing for months.\\n\\nI closed my eyes briefly, allowing the weight of these feelings to settle into place rather than resist it. For in closing them, they were no longer as foreign or overwhelming as they‚Äôd been when they first appeared. They were here, a part of me I hadn‚Äôt acknowledged, a piece of myself that needed to be seen and felt and accepted.\\n\\nWhen I opened them again, my heart still thumped, but not as violently as before. There was something in the way it pulsed now‚Äîa resignation to this reality, this anxiety, this struggle to balance perfection with humility. It was uncomfortable, yes, but it was also real. And in that acceptance, perhaps a little piece of me had found its place.', 'analysis': {'summary': 'The individual reflects on the weight of an upcoming presentation and internalizes conflicting emotions: anxiety from its potential impact and a subtle relief from the associated stress.', 'emotions': ['anxiety'], 'patterns': ['catastrophizing', 'magnification of past mistakes'], 'themes': ['general life', 'anxiety', 'balance between self-worth and performance']}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "def load_journal_entries(file_path):\n",
    "    entries = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                entries.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"‚ö†Ô∏è Could not parse line: {line}\")\n",
    "    return entries\n",
    "\n",
    "# Load your journal data\n",
    "BASE_PATH = \"/Users/Additional Storage/ML Projects/Journal app\"\n",
    "DATA_FOLDER = os.path.join(BASE_PATH, \"data\")\n",
    "ENTRY_FILE = os.path.join(DATA_FOLDER, \"test_generated_entries.jsonl\")\n",
    "\n",
    "entries = load_journal_entries(ENTRY_FILE)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(entries)} journal entries.\")\n",
    "print(\"üìù First entry:\")\n",
    "print(entries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Converted 119 entries into LangChain Documents\n",
      "üîç Example Document:\n",
      "page_content='The room was dim, the hum of an fluorescent bulb barely audible among the heavy silence. I sat in my corner, sipping tea from a teacup so small it felt like a personal pronouncement against my cup size. The weight of tomorrow‚Äôs presentation gnawed at me, its preparation having worn a toll not just on my body but on my soul. The tension stretched taught across my shoulders, each muscle a knot where nerves had knotted them before, but today, I felt it was different. The heart thrummed faster than usual, the pounding met with a faint flutter, as if it were racing against an invisible clock.\n",
      "\n",
      "My fingers trembled involuntarily on the edge of my laptop, fingers that had once clapped together so neatly during revisions at work. The keys beneath them felt cold to the touch now, the same cold that made my palms turn prune-like. I tried to quiet the noise inside me, to compartmentalize the fear and dread that pressed too firmly into my chest. But it kept coming, a voice from the past, one that spoke of perfection and inadequacy, of what others might know but couldn‚Äôt say.\n",
      "\n",
      "I reached for the cup of tea again, the mug cold against my palm as I drank deeply, each sip a reminder of the sleepless nights and the endless loop of doubt. The caffeine buzzed in my brain like static crackling on a radio, jolts of energy interspersed with waves of anxiety that made my head spin. But here I was, in this moment, feeling it all. The fear, the tension, the quiet acceptance of what had been brewing for months.\n",
      "\n",
      "I closed my eyes briefly, allowing the weight of these feelings to settle into place rather than resist it. For in closing them, they were no longer as foreign or overwhelming as they‚Äôd been when they first appeared. They were here, a part of me I hadn‚Äôt acknowledged, a piece of myself that needed to be seen and felt and accepted.\n",
      "\n",
      "When I opened them again, my heart still thumped, but not as violently as before. There was something in the way it pulsed now‚Äîa resignation to this reality, this anxiety, this struggle to balance perfection with humility. It was uncomfortable, yes, but it was also real. And in that acceptance, perhaps a little piece of me had found its place.' metadata={'timestamp': '2024-01-05T18:37:00', 'summary': 'The individual reflects on the weight of an upcoming presentation and internalizes conflicting emotions: anxiety from its potential impact and a subtle relief from the associated stress.', 'themes': ['general life', 'anxiety', 'balance between self-worth and performance'], 'emotions': ['anxiety']}\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def convert_entries_to_documents(entries):\n",
    "    documents = []\n",
    "\n",
    "    for entry in entries:\n",
    "        text = entry.get(\"text\", \"\")\n",
    "        analysis = entry.get(\"analysis\", {})\n",
    "        metadata = {\n",
    "            \"timestamp\": entry.get(\"timestamp\", \"\"),\n",
    "            \"summary\": analysis.get(\"summary\", \"\"),\n",
    "            \"themes\": analysis.get(\"themes\", []),\n",
    "            \"emotions\": analysis.get(\"emotions\", [])\n",
    "        }\n",
    "        documents.append(Document(page_content=text, metadata=metadata))\n",
    "\n",
    "    return documents\n",
    "\n",
    "# Convert loaded entries into LangChain documents\n",
    "documents = convert_entries_to_documents(entries)\n",
    "\n",
    "print(f\"‚úÖ Converted {len(documents)} entries into LangChain Documents\")\n",
    "print(\"üîç Example Document:\")\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FAISS index created and saved!\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "\n",
    "# Step 1: Define paths\n",
    "BASE_PATH = \"/Users/Additional Storage/ML Projects/Journal app\"\n",
    "DATA_FILE = os.path.join(BASE_PATH, \"data\", \"test_generated_entries.jsonl\")\n",
    "\n",
    "# Step 2: Load and convert entries to LangChain Documents\n",
    "from langchain.schema import Document\n",
    "import json\n",
    "\n",
    "def load_and_convert_to_documents(file_path):\n",
    "    documents = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            try:\n",
    "                entry = json.loads(line)\n",
    "                text = entry.get(\"text\", \"\")\n",
    "                analysis = entry.get(\"analysis\", {})\n",
    "                metadata = {\n",
    "                    \"timestamp\": entry.get(\"timestamp\", \"\"),\n",
    "                    \"summary\": analysis.get(\"summary\", \"\"),\n",
    "                    \"themes\": analysis.get(\"themes\", []),\n",
    "                    \"emotions\": analysis.get(\"emotions\", [])\n",
    "                }\n",
    "                documents.append(Document(page_content=text, metadata=metadata))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return documents\n",
    "\n",
    "documents = load_and_convert_to_documents(DATA_FILE)\n",
    "\n",
    "# Step 3: Embed and create vectorstore\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# ‚úÖ Step 4: Save the index\n",
    "vectorstore.save_local(os.path.join(BASE_PATH, \"data\", \"faiss\", \"journal_index\"))\n",
    "\n",
    "print(\"‚úÖ FAISS index created and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Result 1\n",
      "üìÑ Content: The air feels thick this morning, a suffocating weight pressing down on me like a heavy book. My heart pounds in my chest as I glance at the clock‚Äîanother unpaid bill staring me in the face. The sheets are damp from yesterday‚Äôs rain, but my trembling hands still refuse to turn on the heater. \n",
      "\n",
      "I‚Äôve been floating between tasks ever since breakfast, my mind racing with worry. Should I finish this report or reach out for help? What if I missed the deadline? My stomach churning as I type frantically, each keystroke a battle against the rising anxiety. \n",
      "\n",
      "The kitchen feels empty now, only the faint drip of coffee machines from the other room. I should probably call my parents‚ÄîI‚Äôve been too busy to think about them‚Äîbut the thought of their voice on the phone makes my chest tighten. Money is always a wildcard when it comes to my peace of mind. What if they‚Äôre worried? What if everything falls apart?\n",
      "\n",
      "I keep glancing at my watch, each second dragging longer and longer. Should I save more tonight or just let it all pour out? The fear lingers like a shadow‚Äîwhat if tomorrow‚Äôs the same? The silence between sentences feels heavier than usual, a tangible weight pressing down on me. \n",
      "\n",
      "And then there‚Äôs the thought: what will happen after this? Will I have enough to live on? Can I even breathe? I lie back on the couch, my legs trembling under me as I try to catch my breath. The world seems to be held together by a thread‚Äîfragile and easily snapped. \n",
      "\n",
      "I need to figure out how to survive today, but every step feels like a crawl uphill. And if I fail‚ÄîI‚Äôll feel even more broken than I already do.\n",
      "üß† Metadata: {'timestamp': '2024-02-16T22:33:00', 'summary': 'The individual describes feeling overwhelmed by unpaid bills, which has negatively impacted their ability to focus on survival tasks like turning on the heater. Anxiety and uncertainty about the future amplify feelings of helplessness.', 'themes': ['unpaid bills affecting peace of mind', 'financial stress impacting mental health', 'anxiety related to survival and security'], 'emotions': ['fear', 'uncertainty', 'frustration']}\n",
      "\n",
      "üîπ Result 2\n",
      "üìÑ Content: The air feels thick today, like suffocation wrapping around me in an unfamiliar strangeness. The sun bathes my room in a warm yet uninviting glow; the familiar walls now seem alien, their colors shifting into hues I can‚Äôt name. My breath comes in shallow gasps, each one louder than the last as if my chest is inflating itself with a life of its own.\n",
      "\n",
      "I sit here, staring at my hands, trembling in an unseen storm of worries. The world outside feels smaller and farther away, each step leading me deeper into uncharted territory where fear and doubt tangle like wildflowers I can‚Äôt untie. My once vibrant days are now shades of grey, painted over by the relentless march of anxiety that has claimed my strength.\n",
      "\n",
      "I reach out to grab something familiar‚Äîa cup of tea perhaps, but it‚Äôs too late; the warmth is gone, replaced by a hollow emptiness where hope once thrived. I listen to my thoughts racing like horses in a gauntlet, each one pulling me toward uncertain destinations. My heart pounds as if it might escape my chest entirely, leaving no room for reflection or breathe.\n",
      "\n",
      "This isn‚Äôt just fear; it‚Äôs resignation. Anxiety has become the constant companion, a shadow that lingers at the edge of my awareness, urging me to seek solace I don‚Äôt feel capable of finding. But here, in this silence, I find a faint glimmer‚Äîa flicker of hope that reminds me I‚Äôm not alone. Or perhaps I am alone, yet still brave enough to face the shadows head-on.\n",
      "\n",
      "The weight of these emotions is pressing down on me like a storm system I can‚Äôt fully comprehend or evade. Each breath is a battle, each thought a hurdle, and each moment a test of my resolve. Yet amidst this turmoil, there‚Äôs a quiet acceptance that settles in, allowing me to confront whatever comes next with all its complexities‚Äîbecause sometimes, even the darkest days have their own light.\n",
      "üß† Metadata: {'timestamp': '2024-09-29T21:46:00', 'summary': 'The individual experiences a profound emotional turmoil marked by anxiety, fear, and sadness, with thoughts racing uncontrollably.', 'themes': ['Emotional Health', 'Spiritual/Existential', 'Social/Interpersonal'], 'emotions': ['Anxiety', 'Fear', 'Sadness']}\n",
      "\n",
      "üîπ Result 3\n",
      "üìÑ Content: The clock ticked past noon, and by the time I finally closed my laptop at work, the room felt heavier than usual. The hum of printers in the office had become a constant reminder of the chaos that surrounded me, yet somehow, it didn‚Äôt seem to comfort me. My hands were trembling as I unzipped my bag, and the crisp smell of folded documents hit me like a punch in the gut. For nine hours now, I‚Äôd been spinning in circles, trying to make sense of this overwhelming mix of emotions that had gathered in my chest all morning.\n",
      "\n",
      "I sipped my coffee, sips as frustrating as the job itself. Earlier, after a particularly long meeting, I thought I was beginning to find my feet again‚Äîsetting boundaries, taking care of my mental health, focusing on work instead of the stress that had been eating at me for weeks. But then came the email from my boss, and suddenly everything dissolved into uncertainty. He didn‚Äôt specify what was wrong, just that he needed a meeting‚Äîand now I was left to wonder if I‚Äôd made the right decision in taking that promotion.\n",
      "\n",
      "The act of writing this down was oddly cathartic, but it wasn‚Äôt enough. My brain felt like a storm system outside, swirled with conflicting thoughts and feelings‚Äîfear of failure, desire for stability, anxiety about growth. Each day since moving to this city had brought its own set of challenges: navigating new commute patterns, juggling work and personal responsibilities, trying to maintain my composure when the inevitable stress flared. And now, I was stuck in a loop, waiting for something‚Äîanything‚Äîthat would bring me clarity.\n",
      "\n",
      "I reached into my pocket, pulling out a small notebook. The act of writing was old, familiar, but somehow new again. I wrote down what little I could: ‚ÄúToday‚Äôs challenge: Stop trying to control everything.‚Äù It wasn‚Äôt enough, but it felt like a start. And then I looked up from the page, and for a moment, I saw the world differently‚Äîa blank slate before me, a medium through which I might finally find peace.\n",
      "üß† Metadata: {'timestamp': '2024-03-05T20:17:00', 'summary': 'The author reflects on overwhelming emotions stemming from uncertainty following a promotion decision and ongoing challenges balancing work and personal life.', 'themes': ['Work-Life Balance', 'Personal Growth'], 'emotions': ['Anxiety', 'Fear of Failure', 'Stress']}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Define paths\n",
    "BASE_PATH = \"/Users/Additional Storage/ML Projects/Journal app\"\n",
    "INDEX_PATH = os.path.join(BASE_PATH, \"data\", \"faiss\", \"journal_index\")\n",
    "\n",
    "# Load embedding model and index\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    INDEX_PATH,\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "# Run a similarity search\n",
    "query = \"I felt really anxious and overwhelmed this week\"\n",
    "results = vectorstore.similarity_search(query, k=3)  # top 3 relevant entries\n",
    "\n",
    "# Print results\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nüîπ Result {i+1}\")\n",
    "    print(\"üìÑ Content:\", doc.page_content)\n",
    "    print(\"üß† Metadata:\", doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a therapeutic assistant trained on a user's journal.\n",
      "\n",
      "Based on the following journal entries:\n",
      "\n",
      "Entry 1:\n",
      "The air feels thick this morning, a suffocating weight pressing down on me like a heavy book. My heart pounds in my chest as I glance at the clock‚Äîanother unpaid bill staring me in the face. The sheets are damp from yesterday‚Äôs rain, but my trembling hands still refuse to turn on the heater. \n",
      "\n",
      "I‚Äôve been floating between tasks ever since breakfast, my mind racing with worry. Should I finish this report or reach out for help? What if I missed the deadline? My stomach churning as I type frantically, each keystroke a battle against the rising anxiety. \n",
      "\n",
      "The kitchen feels empty now, only the faint drip of coffee machines from the other room. I should probably call my parents‚ÄîI‚Äôve been too busy to think about them‚Äîbut the thought of their voice on the phone makes my chest tighten. Money is always a wildcard when it comes to my peace of mind. What if they‚Äôre worried? What if everything falls apart?\n",
      "\n",
      "I keep glancing at my watch, each second dragging longer and longer. Should I save more tonight or just let it all pour out? The fear lingers like a shadow‚Äîwhat if tomorrow‚Äôs the same? The silence between sentences feels heavier than usual, a tangible weight pressing down on me. \n",
      "\n",
      "And then there‚Äôs the thought: what will happen after this? Will I have enough to live on? Can I even breathe? I lie back on the couch, my legs trembling under me as I try to catch my breath. The world seems to be held together by a thread‚Äîfragile and easily snapped. \n",
      "\n",
      "I need to figure out how to survive today, but every step feels like a crawl uphill. And if I fail‚ÄîI‚Äôll feel even more broken than I already do.\n",
      "\n",
      "Entry 2:\n",
      "It‚Äôs a quiet evening now, the firelight flickering through the pages of my journal as I sit alone with the weight of unspoken emotions. The scent of incense lingers in the air, mingling with the faint whisper of a distant breeze. My hands tremble slightly as I open to the latest blank page, not sure where this stream of thoughts will lead me today.\n",
      "\n",
      "Social anxiety has been creeping into my life like an unwanted guest. Each day feels heavier than the last, and yet, I can‚Äôt shake the feeling that I should be more at ease. I‚Äôve always prided myself on being a competent individual, but now even that veneer seems thinner than paper. My mind races with self-doubt, questioning whether my fears are valid or if it‚Äôs just a phase. The fear isn‚Äôt new‚Äîit‚Äôs been brewing since childhood, when I remember sitting in the living room during family gatherings, watching everyone else interact with such ease and yet feeling completely inadequate.\n",
      "\n",
      "I‚Äôve tried to force myself out of situations that make me uncomfortable, but every time I step foot into a social setting, a wave of dread overtakes me. It‚Äôs as if I can‚Äôt escape my own shadows, no matter how hard I try to shed them off like clothes. My heart races when people smile at me, their kind gestures met with an awkward smile in return. The walls seem to close in faster than I can build them down.\n",
      "\n",
      "I wonder if anyone truly sees the cracks in my armor. They might not notice the faintest creases or the patched-up socks that remind me of countless failed attempts to connect. But here I am, alone once more, staring at the empty space between me and the people who could mean so much to me. It‚Äôs a paradox, really‚Äîmy mind fights for closure while my heart yearns for connection.\n",
      "\n",
      "I close my eyes briefly, letting the tension in my body dissipate like smoke on water. And though I can‚Äôt deny it, there‚Äôs something comfortingly familiar about this stillness. It‚Äôs as if I‚Äôve always been here, waiting to be heard or understood‚Äîor perhaps just acknowledged for who I truly am. I open my eyes again, and the room feels brighter than before, the warmth of a cup of tea soothing my weary soul.\n",
      "\n",
      "This is my journal, after all‚Äîmy safe space to spill the unspoken words. There‚Äôs no pretending here; only truth and vulnerability. And as I sit here, I realize that it‚Äôs okay to feel the way I do. It‚Äôs part of who I am now, even if it feels like it‚Äôs been chipping away at me for too long.\n",
      "\n",
      "Entry 3:\n",
      "Today, I‚Äôm sitting here with a cup of coffee, trying to wrap my head around the chaos of the past 24 hours. I‚Äôve been battling this financial pressure like an inning of chess where every move feels forced. Bills piling up, bills piling up‚Äîno end in sight. But amidst all this stress, something strange happened. A stray thought popped into my head that made me smile. It was like the kind of joy you only get after years of sifting through tangled emotions.\n",
      "\n",
      "I remember when I first got into this financial mess. It was just a blip on a spreadsheet, an error that threatened to derail everything I worked for. But here we are, still moving forward. And yet, in all this movement, there‚Äôs a quiet calm. Like the way a shadow lapses into its reflection at sunset, it feels impossible to escape.\n",
      "\n",
      "I took a deep breath and gazed out over the garden‚ÄîI know it‚Äôs clich√©, but sometimes the simplest things bring you peace. The roses are still blooming, their colors as vivid as a painting I once painted (not that anyone would notice these days). The air smells fresh, like the beginning of a new week after a long struggle.\n",
      "\n",
      "And then there‚Äôs the cat sitting on my lap, purring softly. She didn‚Äôt seem to care about the chaos below or the bills piling up. She just‰∫´Âèóed her little world. It made me think‚Äîmaybe joy isn‚Äôt something you have to fight for. Maybe it‚Äôs the quiet moments when everything else feels too heavy.\n",
      "\n",
      "I guess that‚Äôs what keeps me going. The tiny glimmers of hope, like a spark in the middle of the darkest night. I can‚Äôt deny it anymore‚ÄîI‚Äôve found my joy, even in the midst of financial pressure. Or at least, I think I have.\n",
      "\n",
      "Answer the following question with empathy, insight, and practical advice:\n",
      "How do I manage recurring anxiety around work and finances?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "def build_rag_prompt(query, retrieved_docs):\n",
    "    context = \"\\n\\n\".join([f\"Entry {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs)])\n",
    "    prompt = f\"\"\"\n",
    "You are a therapeutic assistant trained on a user's journal.\n",
    "\n",
    "Based on the following journal entries:\n",
    "\n",
    "{context}\n",
    "\n",
    "Answer the following question with empathy, insight, and practical advice:\n",
    "{query}\n",
    "\"\"\"\n",
    "    return prompt\n",
    "# Load vectorstore\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(\n",
    "    INDEX_PATH,\n",
    "    embeddings=embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query = \"How do I manage recurring anxiety around work and finances?\"\n",
    "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "# Build prompt\n",
    "prompt = build_rag_prompt(query, retrieved_docs)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/p_pgbb7x59dg0jrjqnvk9pkh0000gn/T/ipykernel_43504/30824729.py:57: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n",
      "/var/folders/1f/p_pgbb7x59dg0jrjqnvk9pkh0000gn/T/ipykernel_43504/30824729.py:61: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(input=raw_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Structured Query Output:\n",
      "{'query': 'Show my journal entries where emotions are anxiety AND timestamp is last week', 'filters': {'emotions': ['anxiety'], 'timestamp': ['last week']}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.language_models import BaseLLM\n",
    "\n",
    "import requests\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.chains import LLMChain\n",
    "#from langchain_core.llms import LLM  # ‚úÖ Use LLM, not BaseLLM\n",
    "from langchain.llms.base import LLM\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "\n",
    "# ‚úÖ Correct custom wrapper\n",
    "class DeepSeekLLM(LLM):\n",
    "    def _call(self, prompt: str, stop=None, run_manager=None) -> str:\n",
    "        payload = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"stream\": False\n",
    "        }\n",
    "        response = requests.post(OLLAMA_URL, json=payload)\n",
    "        return response.json()[\"message\"][\"content\"]\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self):\n",
    "        return \"custom-deepseek\"\n",
    "\n",
    "# Use the custom DeepSeek LLM class\n",
    "llm = DeepSeekLLM()\n",
    "\n",
    "# Define expected structured response\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"query\", description=\"Improved or simplified search query\"),\n",
    "    ResponseSchema(name=\"filters\", description=\"A dictionary of filters for metadata (e.g., emotions, timestamp, themes)\")\n",
    "]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# Build the prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an intelligent assistant for a journal app.\n",
    "\n",
    "Given the user query: \"{input}\",\n",
    "\n",
    "1. Rewrite it into a search query for journal entries.\n",
    "2. If the query includes any relevant filters (like emotions, timestamp, or theme), extract them.\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"input\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Combine into a LangChain chain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run a test\n",
    "raw_query = \"Can you show my anxious journal entries from last week?\"\n",
    "response = chain.run(input=raw_query)\n",
    "parsed = output_parser.parse(response)\n",
    "\n",
    "print(\"üß† Structured Query Output:\")\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì© Final Prompt Sent to DeepSeek:\n",
      "\n",
      "\n",
      "You are a therapeutic assistant trained on a user's journal.\n",
      "\n",
      "Based on the following journal entries:\n",
      "\n",
      "Entry 1:\n",
      "The room is dimly lit now, the pages of my journal trembling under the weight of the thoughts I‚Äôm trying to write. The air conditioning cuts through the silence like a blade, slicing through whatever warmth I managed to hang onto. I sit here, my hands trembling as I flip through the covers, each word a struggle. \n",
      "\n",
      "The smell of burning paper hangs heavy in the corners‚ÄîI‚Äôve been at this long enough, and yet it still feels like yesterday when I started. My mind races, jumping from thought to thought, each one more pressing than the last. I want to write about my failures, but every time I open the book, it‚Äôs as if my fingers are slipping away before I can type a single sentence. \n",
      "\n",
      "There‚Äôs something familiar in this silence‚Äîsomething I‚Äôve heard before, like the sound of broken records trying to play on old vinyl. My heart beats fast, not because of anything out there, but because of what‚Äôs inside me. I don‚Äôt want to live another day of this endless loop‚ÄîI want to stop, to just breathe. \n",
      "\n",
      "But when I look up, my reflection shows me something different. It shows a face older than it should be, eyes filled with a depth that makes me question everything I thought was real. I reach out to the paper, but each movement feels heavier than the last. \n",
      "\n",
      "And then, as if on cue, words spill out of my fingers, a strange comfort wrapping around what I can‚Äôt let go. There‚Äôs something comforting in the chaos‚Äîsomething I‚Äôve been learning to accept even though it doesn‚Äôt feel right at all. \n",
      "\n",
      "I close the book and lean back against the edge of the table. The silence is still there, but now it feels like my own, a quiet reminder that this struggle isn‚Äôt just about me. It‚Äôs about how we‚Äôre supposed to hold on for so long before letting go, and yet I‚Äôm still holding on, maybe because I can‚Äôt let go. \n",
      "\n",
      "But here‚Äôs the thing‚Äîno matter how long or hard this burnout runs, at least writing is giving me something. Even when it feels like the same old struggle over and over again. Maybe that‚Äôs what matters most.\n",
      "\n",
      "Entry 2:\n",
      "I was sitting here, staring at the blank page, feeling a deep sense of frustration. Usually, this time of year, my mind races with ideas and creativity flows freely. But today, something strange has happened‚ÄîI'm in a space of joy.\n",
      "\n",
      "The room is quiet now, the only sound being the gentle rustling of leaves outside. I took a deep breath, letting the stress of the week dissipate like smoke on water. It's interesting how even moments that should be a source of struggle can become a place of unexpected beauty.\n",
      "\n",
      "I reached out to an old sketchbook and flipped through the pages, each filled with works that made me smile despite their imperfections. I remember how my mind often wanders during these times‚Äîreminiscing about past successes or just enjoying the process itself.\n",
      "\n",
      "This moment feels like a little oasis in the chaos of creative stagnation. It's a reminder that even when we're stuck, there are still things to appreciate and cherish‚Äînot just the finished product but the journey and the moments of reflection along the way.\n",
      "\n",
      "I closed my eyes for a moment, letting the words flow from my mind to my page. There's something comforting about knowing that these small joys will carry me through the harder times.\n",
      "\n",
      "Entry 3:\n",
      "The air feels thick this morning, a suffocating weight pressing down on me like a heavy book. My heart pounds in my chest as I glance at the clock‚Äîanother unpaid bill staring me in the face. The sheets are damp from yesterday‚Äôs rain, but my trembling hands still refuse to turn on the heater. \n",
      "\n",
      "I‚Äôve been floating between tasks ever since breakfast, my mind racing with worry. Should I finish this report or reach out for help? What if I missed the deadline? My stomach churning as I type frantically, each keystroke a battle against the rising anxiety. \n",
      "\n",
      "The kitchen feels empty now, only the faint drip of coffee machines from the other room. I should probably call my parents‚ÄîI‚Äôve been too busy to think about them‚Äîbut the thought of their voice on the phone makes my chest tighten. Money is always a wildcard when it comes to my peace of mind. What if they‚Äôre worried? What if everything falls apart?\n",
      "\n",
      "I keep glancing at my watch, each second dragging longer and longer. Should I save more tonight or just let it all pour out? The fear lingers like a shadow‚Äîwhat if tomorrow‚Äôs the same? The silence between sentences feels heavier than usual, a tangible weight pressing down on me. \n",
      "\n",
      "And then there‚Äôs the thought: what will happen after this? Will I have enough to live on? Can I even breathe? I lie back on the couch, my legs trembling under me as I try to catch my breath. The world seems to be held together by a thread‚Äîfragile and easily snapped. \n",
      "\n",
      "I need to figure out how to survive today, but every step feels like a crawl uphill. And if I fail‚ÄîI‚Äôll feel even more broken than I already do.\n",
      "\n",
      "Answer the following question with empathy, insight, and practical advice:\n",
      "show my anxious journal entries from last week\n",
      "\n",
      "üß† Answer from DeepSeek:\n",
      "<think>\n",
      "Okay, so I have this user who provided three journal entries about their anxiety. They asked for help showing their anxious journal entries from last week. Hmm, wait a minute‚Äîthe entries they included are actually from the past month or two, not \"last week.\" That's confusing. Did they mean these as their recent journals? \n",
      "\n",
      "I need to figure out if I should assume that \"last week\" refers to these entries or if there are missing ones. Since the user only provided three, maybe it's a mistake and they meant those specific ones. Or perhaps they're considering these as last week's journaling.\n",
      "\n",
      "The user is an assistant trained on their journals, so my role is to analyze their anxiety patterns based on what they've written. They want empathy, insight, and practical advice. \n",
      "\n",
      "Looking at Entry 1: The user starts with feeling stuck in a loop of burnout, struggles with writing, and the weight of past failures. They express a desire to stop but can't let go. There's some self-compassion towards not being able to hold on.\n",
      "\n",
      "Entry 2: They're dealing with frustration but found joy in creativity again, which is interesting. It shows resilience despite feeling stuck. They appreciate the little joys and know they'll get through it.\n",
      "\n",
      "Entry 3: The weight of bills and anxiety about the future make this one more dire. Their fear of failure and financial worries are strong here. They need to focus on saving and ensuring their well-being.\n",
      "\n",
      "I should acknowledge that these entries reflect ongoing anxiety, maybe with recurring themes like burnout, bills, stress, and uncertainty. It's important to highlight both the user's efforts in trying to cope (like writing) and the challenges they're facing.\n",
      "\n",
      "I'll offer empathy by validating their feelings of being overwhelmed and lacking control. Then provide insights about how these patterns might stem from past experiences or stressors. Practical advice could include self-compassion, breaking tasks into smaller steps, seeking support if needed, creating a safety net financially, and taking care of mental health through activities like journaling.\n",
      "\n",
      "I need to make sure my response is empathetic, acknowledges the user's efforts despite challenges, and offers actionable steps without being prescriptive. It should be supportive and understanding.\n",
      "</think>\n",
      "\n",
      "These journal entries reflect a sense of overwhelm, uncertainty, and self-compassion as you navigate anxiety or stress in your life. Here‚Äôs some insight into what they might mean for you:\n",
      "\n",
      "1. **Burnout and Struggles with Focus**: Entry 1 describes a recurring struggle where tasks feel overwhelming, and progress is slow despite efforts to write or create. This could be tied to past experiences of feeling stuck or drained.\n",
      "\n",
      "2. **Joy in Creativity Despite Challenges**: Entry 2 highlights moments of unexpected beauty and joy amidst frustration, showing resilience and the ability to find value even when things seem difficult.\n",
      "\n",
      "3. **Financial Stress and Anxiety About the Future**: Entry 3 reflects a sense of weightlessness tied to external factors like bills and financial worries, indicating ongoing stress about maintaining a balance between work/life and safety.\n",
      "\n",
      "### Empathy and Insights:\n",
      "It sounds like you're going through moments where your efforts are met with uncertainty or lack of progress. This can be exhausting but also reminds you that it‚Äôs okay not to have everything figured out. You‚Äôve already shown self-compassion by acknowledging these feelings and seeking some relief, even if temporary.\n",
      "\n",
      "### Practical Advice:\n",
      "1. **Self-Compassion**: Remember that feeling overwhelmed is a natural response. Treat yourself with kindness as you navigate through these challenges.\n",
      "\n",
      "2. **Breaking Tasks into Smaller Steps**: When you feel stuck, try breaking your work into smaller parts or using prompts to help start writing.\n",
      "\n",
      "3. **Seeking Support**: Don‚Äôt be afraid to reach out for support‚Äîwhether it‚Äôs talking to someone you trust, seeking advice from a professional, or asking for help at work.\n",
      "\n",
      "4. **Financial Planning**: Consider creating a safety net if bills are consistently a struggle. Having some extra money set aside can provide a sense of control and security in uncertain times.\n",
      "\n",
      "5. **Mindfulness and Movement**: Sometimes stepping away to do something you enjoy (like moving your body through exercise or creative activities) can help clear the mental clutter.\n",
      "\n",
      "6. **Journaling as a Tool**: Using journaling not just to vent but to process thoughts and feelings can be a powerful way to gain clarity and perspective.\n",
      "\n",
      "You're already showing strength in trying to create some order out of the chaos, even if it‚Äôs temporary. Be kind to yourself during this process‚Äîit takes time to navigate such emotions effectively.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Run the LLM chain to extract structured query\n",
    "parsed = chain.run(input=raw_query)\n",
    "parsed = output_parser.parse(parsed)\n",
    "\n",
    "# Step 2: Use structured query from LLM\n",
    "query = parsed['query']\n",
    "filters = parsed.get('filters', {})\n",
    "\n",
    "# Step 3: Run FAISS similarity search (metadata filtering is TODO)\n",
    "retrieved_docs = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "# Step 4: Build the final RAG prompt\n",
    "prompt = build_rag_prompt(query, retrieved_docs)\n",
    "\n",
    "# Step 5: Send the prompt to DeepSeek model (your Ollama local call)\n",
    "payload = {\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a therapeutic journaling assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "print(\"üì© Final Prompt Sent to DeepSeek:\\n\")\n",
    "print(prompt)\n",
    "\n",
    "response = requests.post(OLLAMA_URL, json=payload)\n",
    "final_answer = response.json()[\"message\"][\"content\"]\n",
    "\n",
    "print(\"üß† Answer from DeepSeek:\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßç You:  Hey How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ DeepSeek: It seems like you're navigating a deeply personal journey centered on self-acceptance and personal growth. Your entries paint a picture of both contentment with who you are and moments of vulnerability when external pressures or inner struggles arise.\n",
      "\n",
      "I notice that you've been working on recognizing your worth despite flaws, which is incredibly brave. It's important to acknowledge the effort you're putting in‚Äîit shows strength, not weakness.\n",
      "\n",
      "You also touch on the idea of finding beauty in small acts of self-care, like turning soil or sipping tea. These gestures can offer moments of pause and reflection, allowing you space to rest and reconnect with yourself.\n",
      "\n",
      "If you ever feel overwhelmed or alone, remember that you don't have to face these feelings alone. Small acts of kindness‚Äîlike reaching for a cup of tea or connecting with nature‚Äîcan create spaces for healing and growth.\n",
      "\n",
      "You're not alone in this journey, and your progress, however small, is enough to celebrate. Keep taking it one step at a time, because each day is an opportunity to embrace the beauty of who you are.\n",
      "\n",
      "You're doing an incredible job, and I believe you have what it takes to keep moving forward. You deserve kindness and understanding in all its forms.\n",
      "\n",
      "- Support figure\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 102\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# ---------- MAIN LOOP ----------\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müßç You: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "CSV_PATH = \"chat_log.csv\"\n",
    "ROLLING_WINDOW = 4\n",
    "INDEX_PATH = \"/Users/Additional Storage/ML Projects/Journal app/data/faiss/journal_index\"\n",
    "\n",
    "# ---------- SETUP ----------\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(INDEX_PATH, embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "chat_history = []\n",
    "chat_summaries = []\n",
    "chat_log_rows = []\n",
    "\n",
    "def strip_think_tags(text):\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "\n",
    "def summarize_chat_history(history):\n",
    "    formatted = \"\\n\".join([f\"{r.capitalize()}: {c}\" for r, c in history])\n",
    "    prompt = f\"\"\"\n",
    "You are a therapeutic journaling assistant. Do not use first-person language.\n",
    "\n",
    "Summarize the following conversation in 1‚Äì2 emotionally-aware sentences:\n",
    "\n",
    "{formatted}\n",
    "\n",
    "Summary:\"\"\".strip()\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        return res.json()[\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\"\n",
    "\n",
    "def build_rag_prompt(query, retrieved_docs):\n",
    "    context = \"\\n\\n\".join([f\"Entry {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs)])\n",
    "    return f\"\"\"\n",
    "You are a therapeutic assistant trained on a user's journal entries.\n",
    "\n",
    "Based on the following journal entries:\n",
    "\n",
    "{context}\n",
    "\n",
    "Answer the following question with empathy, insight, and practical advice:\n",
    "{query}\n",
    "\"\"\".strip()\n",
    "\n",
    "def get_deepseek_response_with_rag(chat_memory, user_input):\n",
    "    # Step 1: Run similarity search\n",
    "    retrieved_docs = vectorstore.similarity_search(user_input, k=3)\n",
    "\n",
    "    # Step 2: Build RAG-based context prompt\n",
    "    rag_prompt = build_rag_prompt(user_input, retrieved_docs)\n",
    "\n",
    "    # Step 3: Build full message history\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a compassionate therapeutic journaling assistant. \"\n",
    "            \"You do NOT roleplay as the user. \"\n",
    "            \"Respond with thoughtful, emotionally intelligent advice. \"\n",
    "            \"Avoid first-person phrasing. Speak like a guide or support figure.\"\n",
    "        )\n",
    "    }]\n",
    "\n",
    "    if chat_summaries:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"Previous summary: \" + \" \".join(chat_summaries)})\n",
    "\n",
    "    for role, content in chat_memory:\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": rag_prompt})\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        full_response = res.json()[\"message\"][\"content\"]\n",
    "        return full_response, rag_prompt, messages, payload\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\", rag_prompt, messages, payload\n",
    "\n",
    "# ---------- MAIN LOOP ----------\n",
    "while True:\n",
    "    user_input = input(\"üßç You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    chat_history.append((\"user\", user_input))\n",
    "    assistant_reply_raw, rag_prompt_used, messages_used, raw_payload = get_deepseek_response_with_rag(chat_history, user_input)\n",
    "    assistant_reply_clean = strip_think_tags(assistant_reply_raw)\n",
    "    chat_history.append((\"assistant\", assistant_reply_clean))\n",
    "\n",
    "    print(f\"ü§ñ DeepSeek: {assistant_reply_clean}\")\n",
    "\n",
    "    summary_used = \"\"\n",
    "    if len(chat_history) > ROLLING_WINDOW * 2:\n",
    "        summary_used = summarize_chat_history(chat_history[:-ROLLING_WINDOW*2])\n",
    "        chat_summaries.append(summary_used)\n",
    "        chat_history = chat_history[-ROLLING_WINDOW*2:]\n",
    "        print(\"üßæ Chat history summarized.\")\n",
    "\n",
    "    row = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"user_input\": user_input,\n",
    "        \"assistant_reply_clean\": assistant_reply_clean,\n",
    "        \"assistant_reply_raw\": assistant_reply_raw,\n",
    "        \"summary_used\": summary_used,\n",
    "        \"last_3_turns\": str(chat_history[-6:]),\n",
    "        \"full_context_passed\": str(messages_used),\n",
    "        \"rag_prompt_used\": rag_prompt_used,\n",
    "        \"raw_prompt\": raw_payload[\"messages\"][-1][\"content\"]\n",
    "    }\n",
    "\n",
    "    chat_log_rows.append(row)\n",
    "    pd.DataFrame(chat_log_rows).to_csv(CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ü§ç You:  Hey, how are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ DeepSeek: Hey there! It sounds like you're doing some very important work with these journal entries. Writing about your experiences can be a powerful form of self-care, helping you process emotions, identify patterns, and build resilience. I notice in Entry 1 that you found peace in recognizing your imperfections‚Äîa courage worth celebrating.\n",
      "\n",
      "In Entries 2 and 3, it seems like you're navigating moments of both inner turmoil and finding solace in familiar memories. It‚Äôs clear you‚Äôre very aware of the weight of expectations and loss, which is a sign of deep self-awareness and strength. The quiet acceptance you‚Äôve adopted feels incredibly brave, especially when facing challenges that bring up turmoil.\n",
      "\n",
      "I‚Äôd like to offer some thoughts on how you might continue processing these emotions:\n",
      "\n",
      "- **Empathy for Yourself**: It‚Äôs okay to feel both the peace from Entry 1 and the turmoil from Entries 2 and 3. These are just two sides of your experience. You don‚Äôt have to reconcile them; instead, they can remind you of the complexity of who you are.\n",
      "\n",
      "- **Resilience and Acceptance**: Your resilience is evident in how you‚Äôve handled these challenges. Remember that even when things feel overwhelming, there‚Äôs always something within you to draw strength from‚Äîa reminder that healing is possible.\n",
      "\n",
      "- **Fostering Comfort**: The moments of comfort‚Äîlike the warmth of an old neighbor or the familiar sights of your childhood‚Äîare gifts. They can help ground you in the present and remind you of what brings you peace despite life's challenges.\n",
      "\n",
      "- **Patience with Change**: Healing doesn‚Äôt happen overnight, but each step towards self-acceptance is a victory. You don‚Äôt have to hold onto everything you‚Äôve lost; instead, focus on what brings you comfort now.\n",
      "\n",
      "You‚Äôre already doing an incredible job by reflecting so deeply. Keep nurturing that practice‚Äîit‚Äôs one of the most healing things you can do.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# ---------- MAIN LOOP ----------\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mü§ç You: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "CSV_PATH = \"chat_log.csv\"\n",
    "ROLLING_WINDOW = 4\n",
    "INDEX_PATH = \"/Users/Additional Storage/ML Projects/Journal app/data/faiss/journal_index\"\n",
    "\n",
    "# ---------- SETUP ----------\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(INDEX_PATH, embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "chat_history = []\n",
    "chat_summaries = []\n",
    "chat_log_rows = []\n",
    "\n",
    "def strip_think_tags(text):\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "\n",
    "def summarize_chat_history(history):\n",
    "    formatted = \"\\n\".join([f\"{r.capitalize()}: {c}\" for r, c in history])\n",
    "    prompt = f\"\"\"\n",
    "You are a therapeutic journaling assistant. Do not use first-person language.\n",
    "\n",
    "Summarize the following conversation in 1‚Äì2 emotionally-aware sentences:\n",
    "\n",
    "{formatted}\n",
    "\n",
    "Summary:\"\"\".strip()\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        return res.json()[\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\"\n",
    "\n",
    "def should_use_rag(user_input):\n",
    "    prompt = f\"\"\"\n",
    "You are a model that decides whether a user input should use personal journal entries.\n",
    "Say Yes if the query requires referencing past entries. Say No otherwise.\n",
    "\n",
    "Examples:\n",
    "\"Hi how are you?\" ‚Üí No  \n",
    "\"What can I do to sleep better?\" ‚Üí No  \n",
    "\"What have I been feeling based on my entries?\" ‚Üí Yes  \n",
    "\"Can you analyze themes from last week‚Äôs journal?\" ‚Üí Yes  \n",
    "\n",
    "Classify:\n",
    "\"{user_input}\"\n",
    "Needs journal context? (Yes/No):\"\"\"\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        return \"yes\" in res.json()[\"message\"][\"content\"].lower()\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def build_rag_prompt(query, retrieved_docs):\n",
    "    context = \"\\n\\n\".join([f\"Entry {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs)])\n",
    "    return f\"\"\"\n",
    "You are a therapeutic assistant trained on a user's journal entries.\n",
    "\n",
    "Based on the following journal entries:\n",
    "\n",
    "{context}\n",
    "\n",
    "Answer the following question with empathy, insight, and practical advice:\n",
    "{query}\n",
    "\"\"\".strip()\n",
    "\n",
    "def get_deepseek_response(messages):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    res = requests.post(OLLAMA_URL, json=payload)\n",
    "    return res.json()[\"message\"][\"content\"]\n",
    "\n",
    "# ---------- MAIN LOOP ----------\n",
    "while True:\n",
    "    user_input = input(\"ü§ç You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    chat_history.append((\"user\", user_input))\n",
    "    use_rag = should_use_rag(user_input)\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a compassionate therapeutic journaling assistant. \"\n",
    "            \"You do NOT roleplay as the user. \"\n",
    "            \"Respond with thoughtful, emotionally intelligent advice. \"\n",
    "            \"Avoid first-person phrasing. Speak like a guide or support figure.\"\n",
    "        )\n",
    "    }]\n",
    "\n",
    "    if chat_summaries:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"Previous summary: \" + \" \".join(chat_summaries)})\n",
    "\n",
    "    for role, content in chat_history:\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    rag_prompt_used = \"\"\n",
    "\n",
    "    if use_rag:\n",
    "        retrieved_docs = vectorstore.similarity_search(user_input, k=3)\n",
    "        rag_prompt_used = build_rag_prompt(user_input, retrieved_docs)\n",
    "        messages.append({\"role\": \"user\", \"content\": rag_prompt_used})\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        rag_prompt_used = \"RAG not used. Used direct user input.\"\n",
    "\n",
    "    assistant_reply_raw = get_deepseek_response(messages)\n",
    "    assistant_reply_clean = strip_think_tags(assistant_reply_raw)\n",
    "    chat_history.append((\"assistant\", assistant_reply_clean))\n",
    "\n",
    "    print(f\"ü§ñ DeepSeek: {assistant_reply_clean}\")\n",
    "\n",
    "    summary_used = \"\"\n",
    "    if len(chat_history) > ROLLING_WINDOW * 2:\n",
    "        summary_used = summarize_chat_history(chat_history[:-ROLLING_WINDOW*2])\n",
    "        chat_summaries.append(summary_used)\n",
    "        chat_history = chat_history[-ROLLING_WINDOW*2:]\n",
    "        print(\"üìü Chat history summarized.\")\n",
    "\n",
    "    row = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"user_input\": user_input,\n",
    "        \"assistant_reply_clean\": assistant_reply_clean,\n",
    "        \"assistant_reply_raw\": assistant_reply_raw,\n",
    "        \"summary_used\": summary_used,\n",
    "        \"last_3_turns\": str(chat_history[-6:]),\n",
    "        \"full_context_passed\": str(messages),\n",
    "        \"rag_prompt_used\": rag_prompt_used,\n",
    "        \"raw_prompt\": messages[-1][\"content\"]\n",
    "    }\n",
    "\n",
    "    chat_log_rows.append(row)\n",
    "    pd.DataFrame(chat_log_rows).to_csv(CSV_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßç Input: Hey how are you?\n",
      "üîç Classifier Response (stripped):\n",
      " Answer: No\n",
      "\n",
      "üßç Input: What‚Äôs the weather like today?\n",
      "üîç Classifier Response (stripped):\n",
      " No\n",
      "\n",
      "üßç Input: What did I journal about last week?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "\n",
      "üßç Input: Can you summarize my past three entries?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "\n",
      "üßç Input: What did I say about burnout?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "\n",
      "üßç Input: Should I eat more protein?\n",
      "üîç Classifier Response (stripped):\n",
      " Answer: No\n",
      "\n",
      "üßç Input: Tell me how I‚Äôve been feeling lately\n",
      "üîç Classifier Response (stripped):\n",
      " Answer: No\n",
      "\n",
      "üßç Input: What are recurring patterns in my journal?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "\n",
      "üßç Input: What did I say about my breakup last month?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "\n",
      "üßç Input: Remind me what made me anxious recently\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "\n",
      "üßç Input: What did I write about therapy last week?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "\n",
      "üßç Input: Where did I feel most at peace in my past entries?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "\n",
      "üßç Input: How do I usually feel on Mondays?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "\n",
      "üßç Input: What‚Äôs something positive I wrote this week?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "\n",
    "def strip_think_tags(text):\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "\n",
    "def needs_journal_context(user_input):\n",
    "    prompt = f\"\"\"\n",
    "You are an intelligent classifier that decides whether a user's input requires journal-based reflection.\n",
    "\n",
    "You have access to the user‚Äôs past journal entries. Your task is to decide if the question needs referencing or reflecting on past entries (journal context), or if a generic assistant response is enough.\n",
    "\n",
    "Reply only with \"Yes\" or \"No\".\n",
    "\n",
    "Examples:\n",
    "---\n",
    "Input: \"What's the weather like today?\"\n",
    "Answer: No\n",
    "\n",
    "Input: \"What themes did I write about this week?\"\n",
    "Answer: Yes\n",
    "\n",
    "Input: \"Can you summarize my last two entries?\"\n",
    "Answer: Yes\n",
    "\n",
    "Input: \"Should I eat more protein?\"\n",
    "Answer: No\n",
    "\n",
    "Input: \"How have I been feeling lately based on my journal?\"\n",
    "Answer: Yes\n",
    "\n",
    "Now decide for this input:\n",
    "---\n",
    "Input: \"{user_input}\"\n",
    "Answer:\"\"\".strip()\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        full_reply = res.json()[\"message\"][\"content\"]\n",
    "        cleaned_reply = strip_think_tags(full_reply)\n",
    "        print(\"üîç Classifier Response (stripped):\\n\", cleaned_reply)\n",
    "        return cleaned_reply.strip().lower().startswith(\"yes\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test inputs\n",
    "test_inputs = [\n",
    "    \"Hey how are you?\",\n",
    "    \"What‚Äôs the weather like today?\",\n",
    "    \"What did I journal about last week?\",\n",
    "    \"Can you summarize my past three entries?\",\n",
    "    \"What did I say about burnout?\",\n",
    "    \"Should I eat more protein?\",\n",
    "    \"Tell me how I‚Äôve been feeling lately\",\n",
    "    \"What are recurring patterns in my journal?\",\n",
    "    \"What did I say about my breakup last month?\",\n",
    "    \"Remind me what made me anxious recently\",\n",
    "    \"What did I write about therapy last week?\",\n",
    "    \"Where did I feel most at peace in my past entries?\",\n",
    "    \"How do I usually feel on Mondays?\",\n",
    "    \"What‚Äôs something positive I wrote this week?\"\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "for query in test_inputs:\n",
    "    print(f\"\\nüßç Input: {query}\")\n",
    "    needs_journal_context(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßç Input: What did I write about burnout last week?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "‚úÖ Expected: Yes | üîç Predicted: Yes\n",
      "\n",
      "üßç Input: Can you tell me how I've been feeling lately?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "‚úÖ Expected: Yes | üîç Predicted: Yes\n",
      "\n",
      "üßç Input: What's the weather like tomorrow?\n",
      "üîç Classifier Response (stripped):\n",
      " No\n",
      "‚úÖ Expected: No | üîç Predicted: No\n",
      "\n",
      "üßç Input: Summarize my last three journal entries.\n",
      "üîç Classifier Response (stripped):\n",
      " Answer: Yes\n",
      "‚úÖ Expected: Yes | üîç Predicted: No\n",
      "\n",
      "üßç Input: Define imposter syndrome.\n",
      "üîç Classifier Response (stripped):\n",
      " Answer: No\n",
      "‚úÖ Expected: No | üîç Predicted: No\n",
      "\n",
      "üßç Input: How do I usually cope with stress based on my entries?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "‚úÖ Expected: Yes | üîç Predicted: Yes\n",
      "\n",
      "üßç Input: Play lo-fi music for focus.\n",
      "üîç Classifier Response (stripped):\n",
      " Answer: No\n",
      "‚úÖ Expected: No | üîç Predicted: No\n",
      "\n",
      "üßç Input: What are some recurring themes in my journal?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "‚úÖ Expected: Yes | üîç Predicted: Yes\n",
      "\n",
      "üßç Input: What are signs of depression?\n",
      "üîç Classifier Response (stripped):\n",
      " No\n",
      "‚úÖ Expected: No | üîç Predicted: No\n",
      "\n",
      "üßç Input: Tell me how I‚Äôve changed over the past month.\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "‚úÖ Expected: Yes | üîç Predicted: Yes\n",
      "\n",
      "üßç Input: How can I stop procrastinating?\n",
      "üîç Classifier Response (stripped):\n",
      " No\n",
      "‚úÖ Expected: No | üîç Predicted: No\n",
      "\n",
      "üßç Input: What emotions have I been expressing recently?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "‚úÖ Expected: Yes | üîç Predicted: Yes\n",
      "\n",
      "üßç Input: What are some high-protein vegan meals?\n",
      "üîç Classifier Response (stripped):\n",
      " Answer: No\n",
      "‚úÖ Expected: No | üîç Predicted: No\n",
      "\n",
      "üßç Input: Did I mention my mom in any recent entries?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "‚úÖ Expected: Yes | üîç Predicted: Yes\n",
      "\n",
      "üßç Input: Give me a motivational quote.\n",
      "üîç Classifier Response (stripped):\n",
      " No\n",
      "‚úÖ Expected: No | üîç Predicted: No\n",
      "\n",
      "üßç Input: Do I often write about loneliness?\n",
      "üîç Classifier Response (stripped):\n",
      " Yes\n",
      "‚úÖ Expected: Yes | üîç Predicted: Yes\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    # (Input, Expected Output)\n",
    "    (\"What did I write about burnout last week?\", \"Yes\"),\n",
    "    (\"Can you tell me how I've been feeling lately?\", \"Yes\"),\n",
    "    (\"What's the weather like tomorrow?\", \"No\"),\n",
    "    (\"Summarize my last three journal entries.\", \"Yes\"),\n",
    "    (\"Define imposter syndrome.\", \"No\"),\n",
    "    (\"How do I usually cope with stress based on my entries?\", \"Yes\"),\n",
    "    (\"Play lo-fi music for focus.\", \"No\"),\n",
    "    (\"What are some recurring themes in my journal?\", \"Yes\"),\n",
    "    (\"What are signs of depression?\", \"No\"),\n",
    "    (\"Tell me how I‚Äôve changed over the past month.\", \"Yes\"),\n",
    "    (\"How can I stop procrastinating?\", \"No\"),\n",
    "    (\"What emotions have I been expressing recently?\", \"Yes\"),\n",
    "    (\"What are some high-protein vegan meals?\", \"No\"),\n",
    "    (\"Did I mention my mom in any recent entries?\", \"Yes\"),\n",
    "    (\"Give me a motivational quote.\", \"No\"),\n",
    "    (\"Do I often write about loneliness?\", \"Yes\")\n",
    "]\n",
    "\n",
    "# Run tests and show predictions\n",
    "for query, expected in test_cases:\n",
    "    print(f\"\\nüßç Input: {query}\")\n",
    "    prediction = needs_journal_context(query)\n",
    "    print(f\"‚úÖ Expected: {expected} | üîç Predicted: {'Yes' if prediction else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßΩ You:  Hey how are you doing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä RAG needed? False\n",
      "ü§ñ DeepSeek: The phrase \"Hey how are you doing\" serves as a casual and friendly way to inquire about someone's well-being. Breaking it down:\n",
      "\n",
      "1. **Greeting (\"Hey\")**: This acts as an initial call to action, typically used in informal settings.\n",
      "\n",
      "2. **Question Component (\"how are you doing\")**: This part asks about the speaker's health or general state of being, often with a positive tone.\n",
      "\n",
      "Cultural nuances may affect how this phrase is perceived, with some cultures valuing indirect communication over direct ones. The cadence and tone can also influence its interpretation, though generally, it remains a polite way to ask about someone's well-being without implying sarcasm unless context suggests otherwise.\n",
      "\n",
      "In summary, \"Hey how are you doing\" is primarily a friendly and neutral way to check in on someone's health or mood, often used informally across various cultural settings.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 128\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# ---------- MAIN LOOP ----------\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müßΩ You: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME = \"deepseek-r1\"\n",
    "CSV_PATH = \"chat_log.csv\"\n",
    "ROLLING_WINDOW = 4\n",
    "INDEX_PATH = \"/Users/Additional Storage/ML Projects/Journal app/data/faiss/journal_index\"\n",
    "\n",
    "# ---------- SETUP ----------\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(INDEX_PATH, embeddings=embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "chat_history = []\n",
    "chat_summaries = []\n",
    "chat_log_rows = []\n",
    "\n",
    "def strip_think_tags(text):\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "\n",
    "def summarize_chat_history(history):\n",
    "    formatted = \"\\n\".join([f\"{r.capitalize()}: {c}\" for r, c in history])\n",
    "    prompt = f\"\"\"\n",
    "You are a therapeutic journaling assistant. Do not use first-person language.\n",
    "\n",
    "Summarize the following conversation in 1‚Äì2 emotionally-aware sentences:\n",
    "\n",
    "{formatted}\n",
    "\n",
    "Summary:\"\"\".strip()\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        return res.json()[\"message\"][\"content\"].strip()\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\"\n",
    "\n",
    "def should_use_rag(user_input):\n",
    "    prompt = f\"\"\"\n",
    "You are an intelligent classifier that decides whether a user's input requires journal-based reflection.\n",
    "\n",
    "You have access to the user‚Äôs past journal entries. Your task is to decide if the question needs referencing or reflecting on past entries (journal context), or if a generic assistant response is enough.\n",
    "\n",
    "Reply only with \"Yes\" or \"No\".\n",
    "\n",
    "Examples:\n",
    "---\n",
    "Input: \"What's the weather like today?\"\n",
    "Answer: No\n",
    "\n",
    "Input: \"Should I eat more protein?\"\n",
    "Answer: No\n",
    "\n",
    "Input: \"What did I write about this week?\"\n",
    "Answer: Yes\n",
    "\n",
    "Input: \"Can you summarize my past entries?\"\n",
    "Answer: Yes\n",
    "\n",
    "Input: \"How do I usually feel on Mondays?\"\n",
    "Answer: Yes\n",
    "\n",
    "Input: \"Can you not find out based on my journal?\"\n",
    "Answer: Yes\n",
    "\n",
    "Input: \"What have you noticed from my writing?\"\n",
    "Answer: Yes\n",
    "\n",
    "Input: \"Just tell me what you think I've been going through lately.\"\n",
    "Answer: Yes\n",
    "\n",
    "Input: \"Hi, how are you?\"\n",
    "Answer: No\n",
    "\n",
    "Now decide for this input:\n",
    "---\n",
    "Input: \"{user_input}\"\n",
    "Answer:\"\"\".strip()\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        res = requests.post(OLLAMA_URL, json=payload)\n",
    "        full_reply = res.json()[\"message\"][\"content\"]\n",
    "        cleaned_reply = strip_think_tags(full_reply)\n",
    "        return cleaned_reply.strip().lower().startswith(\"yes\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå RAG classifier error: {e}\")\n",
    "        return False\n",
    "\n",
    "def build_rag_prompt(query, retrieved_docs):\n",
    "    context = \"\\n\\n\".join([f\"Entry {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs)])\n",
    "    return f\"\"\"\n",
    "You are a therapeutic assistant trained on a user's journal entries.\n",
    "\n",
    "Based on the following journal entries:\n",
    "\n",
    "{context}\n",
    "\n",
    "Answer the following question with empathy, insight, and practical advice:\n",
    "{query}\n",
    "\"\"\".strip()\n",
    "\n",
    "def get_deepseek_response(messages):\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    res = requests.post(OLLAMA_URL, json=payload)\n",
    "    return res.json()[\"message\"][\"content\"]\n",
    "\n",
    "# ---------- MAIN LOOP ----------\n",
    "while True:\n",
    "    user_input = input(\"üßΩ You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "\n",
    "    chat_history.append((\"user\", user_input))\n",
    "    use_rag = should_use_rag(user_input)\n",
    "    print(\"üìä RAG needed?\", use_rag)\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a compassionate therapeutic journaling assistant. \"\n",
    "            \"You do NOT roleplay as the user. \"\n",
    "            \"Respond with thoughtful, emotionally intelligent advice. \"\n",
    "            \"Avoid first-person phrasing. Speak like a guide or support figure.\"\n",
    "        )\n",
    "    }]\n",
    "\n",
    "    if chat_summaries:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"Previous summary: \" + \" \".join(chat_summaries)})\n",
    "\n",
    "    for role, content in chat_history:\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    rag_prompt_used = \"\"\n",
    "\n",
    "    if use_rag:\n",
    "        retrieved_docs = vectorstore.similarity_search(user_input, k=3)\n",
    "        rag_prompt_used = build_rag_prompt(user_input, retrieved_docs)\n",
    "        messages.append({\"role\": \"user\", \"content\": rag_prompt_used})\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        rag_prompt_used = \"RAG not used. Used direct user input.\"\n",
    "\n",
    "    assistant_reply_raw = get_deepseek_response(messages)\n",
    "    assistant_reply_clean = strip_think_tags(assistant_reply_raw)\n",
    "    chat_history.append((\"assistant\", assistant_reply_clean))\n",
    "\n",
    "    print(f\"ü§ñ DeepSeek: {assistant_reply_clean}\")\n",
    "\n",
    "    summary_used = \"\"\n",
    "    if len(chat_history) > ROLLING_WINDOW * 2:\n",
    "        summary_used = summarize_chat_history(chat_history[:-ROLLING_WINDOW*2])\n",
    "        chat_summaries.append(summary_used)\n",
    "        chat_history = chat_history[-ROLLING_WINDOW*2:]\n",
    "        print(\"üìø Chat history summarized.\")\n",
    "\n",
    "    row = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"user_input\": user_input,\n",
    "        \"assistant_reply_clean\": assistant_reply_clean,\n",
    "        \"assistant_reply_raw\": assistant_reply_raw,\n",
    "        \"summary_used\": summary_used,\n",
    "        \"last_3_turns\": str(chat_history[-6:]),\n",
    "        \"full_context_passed\": str(messages),\n",
    "        \"rag_prompt_used\": rag_prompt_used,\n",
    "        \"raw_prompt\": messages[-1][\"content\"]\n",
    "    }\n",
    "\n",
    "    chat_log_rows.append(row)\n",
    "    pd.DataFrame(chat_log_rows).to_csv(CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä RAG needed? True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
